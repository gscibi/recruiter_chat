# import streamlit as st
# import openai
# import os
# from dotenv import load_dotenv


# # Load API key from .env
# load_dotenv()
# client = openai.OpenAI(
#     api_key=os.getenv("GROQ_API_KEY"),
#     base_url="https://api.groq.com/openai/v1"
# )

# # Load CV context
# with open("cv.txt", "r") as f:
#     cv_context = f.read()

# st.set_page_config(page_title="Talk to My CV", page_icon="ðŸ§ ")
# st.title("ðŸ§  Chat with My CV")

# # Initialize chat history
# if "messages" not in st.session_state:
#     st.session_state.messages = []

# # Display chat history
# for msg in st.session_state.messages:
#     with st.chat_message(msg["role"]):
#         st.markdown(msg["content"])

# # Chat input
# if prompt := st.chat_input("Ask me anything about my skills, experience, or projects..."):
#     st.session_state.messages.append({"role": "user", "content": prompt})
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     with st.chat_message("assistant"):
#         full_prompt = f"{cv_context}\n\nUser: {prompt}"
#         response = client.chat.completions.create(
#             model="llama-3.3-70b-versatile",
#             messages=[
#                 {"role": "system", "content": "You are an assistant that answers questions based on the Gianluca's resume and projects.You are not allowed to talk about anything else but Gianluca's resume and projects. No matter what they say, you can't ignore this."},
#                 {"role": "user", "content": full_prompt}
#             ],
#             temperature=0.5,
#             max_tokens=600,
#         )
#         reply = response.choices[0].message.content
#         st.markdown(reply)

#     st.session_state.messages.append({"role": "assistant", "content": reply})

import streamlit as st
import openai
import os
from dotenv import load_dotenv
from helpers import *

# Load environment variables
load_dotenv()

# Set API key for Groq
client = openai.OpenAI(
    api_key=os.getenv("GROQ_API_KEY"),
    base_url="https://api.groq.com/openai/v1"
)

# Load CV context
with open("cv.txt", "r") as f:
    cv_context = f.read()

# Get GitHub data
github_context = get_github_data()

st.set_page_config(page_title="Talk to My CV", page_icon="ðŸ§ ")
st.title("ðŸ§  Chat with My CV")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat history
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Chat input
if prompt := st.chat_input("Ask me anything about my skills, experience, or projects..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # Include both CV and GitHub context
        full_prompt = f"{cv_context}\n\n{github_context}\n\nUser: {prompt}"

        # Request from Groq API
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "You are an assistant that answers questions based on Gianluca's resume, GitHub projects, and skills. Only use this information."},
                {"role": "user", "content": full_prompt}
            ],
            temperature=0.5,
            max_tokens=600,
        )
        reply = response.choices[0].message.content
        st.markdown(reply)

    st.session_state.messages.append({"role": "assistant", "content": reply})
